# Learning classifier from dataset:
`version 1.0`  
1. All files generated by step one, divided according to image type are:
    * Read into memory
    * Resized into 28x28 pixel entities(2)
    * Paired with label according to their classification
1. Order of files in corresponding list are randomized
1. After steps 1. and 2. we have 4 separate sets of data according scan type
1. Lists of images are converted into np.arrays and then into matrices of data.
1. Data are subdivided into two sets:
    * 75% to learning
    * 25% to testing
1. We enhance data sets by including rotated, shifted, sheared and zoomed copies of samples
1. Classifier models are compiled, trained, and serialized to disk
1. Classifier parameters are saved as `json` file into classifier directory.

\-\-\-\-\-\-\-\-\-\-\-  
* (2) Stain scaling:  
    Array containing stain has its dimension checked and if:
    * it is lower than desired size image is filled with zeroes, keeping fragment in center (with one pixel top-lef tolerance)
    * it is greater than desired - image is scaled down using `scipy.misc.imresize()` function